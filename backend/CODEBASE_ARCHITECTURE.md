# 2nd Brain - Complete Architecture & Data Flow Summary

**Generated: December 3, 2025**
**Codebase Locations:**
- Frontend: `/Users/rishitjain/Downloads/2nd-brain/frontend`
- Backend: `/Users/rishitjain/Downloads/2nd-brain/backend`

---

## 1. FRONTEND STRUCTURE (Next.js 14 + React 18)

### Architecture Overview
- **Framework**: Next.js 14.0.0 with App Router
- **Styling**: Tailwind CSS 3.3.5
- **HTTP Client**: Axios 1.6.0
- **TypeScript**: 5.2.2
- **Deployment Port**: 3000 (dev)

### Page Structure & Routing

```
/app (Next.js App Router)
â”œâ”€â”€ page.tsx                      # Home page -> ChatInterface component
â”œâ”€â”€ layout.tsx                    # Root layout (basic HTML setup)
â”œâ”€â”€ login/page.tsx               # Login page
â”œâ”€â”€ documents/page.tsx           # Documents listing page
â”œâ”€â”€ projects/page.tsx            # Projects overview page
â”œâ”€â”€ knowledge-gaps/page.tsx       # Knowledge gap identification page
â”œâ”€â”€ training-guides/page.tsx      # Training materials page
â”œâ”€â”€ integrations/page.tsx         # API connectors (Gmail, Slack, GitHub)
â””â”€â”€ settings/page.tsx            # User settings

/components (Reusable UI Components)
â”œâ”€â”€ chat/ChatInterface.tsx        # Main chatbot interface (430 lines)
â”‚   â”œâ”€â”€ Message rendering with sources
â”‚   â”œâ”€â”€ RAG query handling (POST to /api/search)
â”‚   â”œâ”€â”€ Feedback system (thumbs up/down, copy)
â”‚   â”œâ”€â”€ Source citation links
â”‚   â””â”€â”€ Welcome cards with quick actions
â”‚
â”œâ”€â”€ knowledge-gaps/KnowledgeGaps.tsx  # Gap analysis UI (888 lines)
â”‚   â”œâ”€â”€ Voice input (OpenAI Whisper transcription)
â”‚   â”œâ”€â”€ Project-based gap organization
â”‚   â”œâ”€â”€ Gap severity badges (high/medium/low)
â”‚   â”œâ”€â”€ Question type badges
â”‚   â”œâ”€â”€ Answer submission with progress tracking
â”‚   â””â”€â”€ Project expansion/collapse
â”‚
â”œâ”€â”€ documents/Documents.tsx       # Document browser (623 lines)
â”‚   â”œâ”€â”€ Filter by category/status
â”‚   â”œâ”€â”€ Upload new documents
â”‚   â”œâ”€â”€ Document classification review
â”‚   â””â”€â”€ Document detail view
â”‚
â”œâ”€â”€ projects/Projects.tsx         # Project management (401 lines)
â”‚   â”œâ”€â”€ Project clustering display
â”‚   â”œâ”€â”€ Project statistics
â”‚   â”œâ”€â”€ Document count per project
â”‚   â””â”€â”€ Project-specific RAG search
â”‚
â”œâ”€â”€ training-guides/TrainingGuides.tsx  # Training materials (293 lines)
â”‚   â”œâ”€â”€ Generated presentations
â”‚   â”œâ”€â”€ Training videos
â”‚   â””â”€â”€ Download options
â”‚
â”œâ”€â”€ integrations/Integrations.tsx # Data connectors (521 lines)
â”‚   â”œâ”€â”€ Gmail OAuth authentication
â”‚   â”œâ”€â”€ Slack connection
â”‚   â”œâ”€â”€ GitHub integration
â”‚   â””â”€â”€ Sync status monitoring
â”‚
â”œâ”€â”€ settings/Settings.tsx         # User preferences (80 lines)
â”‚   â”œâ”€â”€ Account settings
â”‚   â””â”€â”€ System configuration
â”‚
â”œâ”€â”€ auth/Login.tsx                # Authentication UI (228 lines)
â”‚   â”œâ”€â”€ Login form
â”‚   â””â”€â”€ User validation
â”‚
â””â”€â”€ shared/Sidebar.tsx            # Navigation sidebar (243 lines)
    â”œâ”€â”€ Main menu items
    â”œâ”€â”€ User profile
    â”œâ”€â”€ Settings access
    â””â”€â”€ Active item highlighting
```

### API Communication

**Base URL**: `http://localhost:5003/api`

#### Key Frontend Endpoints Used:

1. **ChatInterface.tsx** calls:
   - `POST /api/search` - RAG query with answer generation
   - `POST /api/feedback` - User feedback on answers
   - `GET /api/document/{doc_id}/view` - View document details

2. **KnowledgeGaps.tsx** calls:
   - `POST /api/transcribe` - Voice-to-text (Whisper)
   - `GET /api/questions` - Fetch knowledge gaps
   - `POST /api/questions/answer` - Submit gap answers
   - `POST /api/projects/{project_id}/gaps` - Project-specific gaps
   - `GET /api/projects` - List projects

3. **Documents.tsx** calls:
   - `POST /api/documents/upload` - Upload documents
   - `GET /api/documents/review` - Review pending docs
   - `POST /api/documents/{doc_id}/decision` - Accept/reject docs
   - `GET /api/documents/categories` - Document categories

4. **Projects.tsx** calls:
   - `GET /api/projects` - All projects
   - `GET /api/projects/{project_id}` - Project details
   - `GET /api/projects/{project_id}/documents` - Project documents

5. **Integrations.tsx** calls:
   - `GET /api/connectors` - List connected sources
   - `POST /api/connectors/add` - Add new connector
   - `GET /api/connectors/gmail/auth` - Gmail OAuth flow
   - `POST /api/connectors/gmail/sync` - Sync Gmail

---

## 2. BACKEND STRUCTURE (Flask + Python ML/NLP)

### Architecture Overview
- **Framework**: Flask + Flask-CORS
- **Python Version**: 3.8+
- **Main Application**: `app_universal.py` (port 5003)
- **LLM**: Azure OpenAI (GPT-5-chat, text-embedding-3-large)
- **Database**: Pickle-based indexes, JSON metadata

### Directory Structure

```
backend/
â”œâ”€â”€ app.py                           # Original Flask app (deprecated)
â”œâ”€â”€ app_universal.py                 # Main production app (2454 lines)
â”œâ”€â”€ app_complete.py                  # Alternative implementation
â”œâ”€â”€ app_project_classification.py     # Project classification only
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                    # Centralized configuration
â”‚       â”œâ”€â”€ BASE_DIR, DATA_DIR, OUTPUT_DIR
â”‚       â”œâ”€â”€ Model paths (embeddings, LLM)
â”‚       â”œâ”€â”€ Clustering parameters (MIN_CLUSTER_SIZE=5, UMAP settings)
â”‚       â”œâ”€â”€ Classification thresholds
â”‚       â”œâ”€â”€ RAG settings (TOP_K_RETRIEVAL=10, RERANK_TOP_K=5)
â”‚       â””â”€â”€ Gap analysis configuration
â”‚
â”œâ”€â”€ rag/                              # Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ enhanced_rag.py              # RAG v1 (basic version)
â”‚   â”œâ”€â”€ enhanced_rag_v2.py           # RAG v2.1 (PRODUCTION)
â”‚   â”‚   â”œâ”€â”€ QueryClassifier - Determines query type & retrieval params
â”‚   â”‚   â”œâ”€â”€ HallucinationDetector - Prevents false claims
â”‚   â”‚   â”œâ”€â”€ CrossEncoderReranker - Re-ranks by relevance
â”‚   â”‚   â”œâ”€â”€ MMRSelector - Maximal Marginal Relevance selection
â”‚   â”‚   â”œâ”€â”€ TemporalAwareness - Boosts recent documents
â”‚   â”‚   â”œâ”€â”€ AdaptiveRetrieval - More sources for complex queries
â”‚   â”‚   â””â”€â”€ Cache for repeated queries
â”‚   â”‚
â”‚   â”œâ”€â”€ hierarchical_rag.py          # Graph + Vector retrieval
â”‚   â”œâ”€â”€ semantic_chunker.py          # Document chunking strategies
â”‚   â”œâ”€â”€ stakeholder_graph.py          # Relationship graph building
â”‚   â””â”€â”€ multimodal.py                # Image/text processing
â”‚
â”œâ”€â”€ gap_analysis/                     # Knowledge gap detection
â”‚   â”œâ”€â”€ gap_analyzer.py              # GapAnalyzer class
â”‚   â”‚   â”œâ”€â”€ analyze_project_gaps() - Find missing info
â”‚   â”‚   â”œâ”€â”€ _create_project_summary() - Summarize docs
â”‚   â”‚   â”œâ”€â”€ _identify_gaps_with_llm() - LLM-based analysis
â”‚   â”‚   â””â”€â”€ _categorize_gaps() - Gap types
â”‚   â”‚
â”‚   â””â”€â”€ question_generator.py         # QuestionGenerator class
â”‚       â”œâ”€â”€ generate_followup_questions() - Create prompts
â”‚       â””â”€â”€ _generate_additional_questions() - LLM generation
â”‚
â”œâ”€â”€ knowledge_capture/                # Exit interview system
â”‚   â””â”€â”€ exit_interview.py             # Structured interview generation
â”‚
â”œâ”€â”€ club_data/                         # BEAT Club data storage
â”‚   â”œâ”€â”€ classified/                   # Classified messages
â”‚   â”‚   â”œâ”€â”€ work/                     # Confirmed work messages
â”‚   â”‚   â”œâ”€â”€ personal/                 # Personal messages
â”‚   â”‚   â”œâ”€â”€ spam/                     # Spam messages
â”‚   â”‚   â”œâ”€â”€ uncertain/                # Uncertain classification
â”‚   â”‚   â”œâ”€â”€ rishi2205/                # User-specific data
â”‚   â”‚   â””â”€â”€ [other-users]/
â”‚   â”‚
â”‚   â”œâ”€â”€ connectors/                   # OAuth tokens, connection state
â”‚   â”‚   â”œâ”€â”€ gmail/
â”‚   â”‚   â”œâ”€â”€ slack/
â”‚   â”‚   â””â”€â”€ github/
â”‚   â”‚
â”‚   â””â”€â”€ search_index.pkl              # TF-IDF search vectors (1.4GB)
â”‚       â””â”€â”€ Contains:
â”‚           â”œâ”€â”€ doc_ids: Document ID list
â”‚           â”œâ”€â”€ doc_vectors: TF-IDF vectors
â”‚           â”œâ”€â”€ doc_index: Document metadata & content
â”‚           â””â”€â”€ vectorizer: sklearn TfidfVectorizer
â”‚
â”œâ”€â”€ data/                              # Original Enron dataset
â”‚   â”œâ”€â”€ employee_clusters/            # Clustered by employee (152 dirs)
â”‚   â”œâ”€â”€ project_clusters/             # Clustered by project (153 dirs)
â”‚   â”œâ”€â”€ unclustered/                  # Flattened documents
â”‚   â”œâ”€â”€ processed/                    # Intermediate results
â”‚   â”œâ”€â”€ search_index.pkl              # Enron search index
â”‚   â””â”€â”€ stakeholder_graph.pkl         # Relationship graph
â”‚
â”œâ”€â”€ src/                               # Modular source code
â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â”œâ”€â”€ employee_clustering.py    # Group by sender/recipient
â”‚   â”‚   â”œâ”€â”€ project_clustering.py     # BERTopic semantic clusters
â”‚   â”‚   â”œâ”€â”€ intelligent_project_clustering.py
â”‚   â”‚   â””â”€â”€ llm_first_clusterer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ work_personal_classifier.py  # GPT-based filtering
â”‚   â”‚   â”œâ”€â”€ project_classifier.py
â”‚   â”‚   â””â”€â”€ global_project_classifier.py
â”‚   â”‚
â”‚   â”œâ”€â”€ gap_analysis/
â”‚   â”‚   â”œâ”€â”€ gap_analyzer.py
â”‚   â”‚   â””â”€â”€ question_generator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge_graph/
â”‚   â”‚   â”œâ”€â”€ knowledge_graph.py         # Neo4j graph builder
â”‚   â”‚   â””â”€â”€ vector_database.py         # ChromaDB indexing
â”‚   â”‚
â”‚   â””â”€â”€ content_generation/
â”‚       â”œâ”€â”€ powerpoint_generator.py    # PPTX creation
â”‚       â”œâ”€â”€ video_generator.py          # MP4 generation
â”‚       â””â”€â”€ gamma_presentation.py       # Specialized format
â”‚
â””â”€â”€ templates/                          # HTML templates (deprecated)
    â””â”€â”€ index.html, etc.
```

---

## 3. DATA ORGANIZATION & STORAGE

### Data Hierarchy

```
BEAT Club Data (Primary)
â”œâ”€â”€ Gmail messages + Slack + GitHub
â”œâ”€â”€ Classified by: work/personal/spam/uncertain
â”œâ”€â”€ Stored in: /club_data/classified/{category}/{username}/
â”œâ”€â”€ Format: JSON lines with metadata
â””â”€â”€ Search Index: club_data/search_index.pkl (1.4GB)

Enron Dataset (Secondary - Historical)
â”œâ”€â”€ Original emails from Enron scandal
â”œâ”€â”€ Stored in: /data/
â”œâ”€â”€ Clustered by:
â”‚   â”œâ”€â”€ Employee (152 clusters)
â”‚   â””â”€â”€ Project (153 clusters)
â””â”€â”€ Search Index: data/search_index.pkl
```

### Data Structures

#### Document/Message Format (JSON)
```json
{
  "metadata": {
    "doc_id": "space_msg_12345",
    "file_name": "message_from_user.txt",
    "source": "gmail",
    "sender": "rishi2205@gmail.com",
    "timestamp": "2025-01-15T10:30:00Z",
    "project": "BEAT Project Alpha",
    "category": "work",
    "classification": {"type": "work", "confidence": 0.94}
  },
  "content": "Full message content...",
  "chunk_id": "doc_001_chunk_1",
  "chunk_seq": 1
}
```

#### Search Index Structure (Pickle)
```python
{
    'doc_ids': [list of 1000s of IDs],
    'doc_vectors': numpy array (n_docs, n_features),
    'doc_index': {
        'doc_id': {
            'metadata': {...},
            'content': "...",
            'cluster_label': 'project_name'
        }
    },
    'vectorizer': TfidfVectorizer instance
}
```

#### Embedding Index (for RAG)
```python
{
    'chunks': [list of text chunks],
    'chunk_ids': [list of chunk IDs],
    'embeddings': numpy array (n_chunks, 3072),  # text-embedding-3-large
    'metadata': [metadata for each chunk]
}
```

#### Knowledge Gaps Format (JSON)
```json
{
  "project_name": "BEAT Project Alpha",
  "gaps": [
    {
      "type": "project_goal",
      "description": "Missing project objectives",
      "severity": "high",
      "is_standard": true
    }
  ],
  "questions": [
    {
      "question": "What were the main goals?",
      "gap_type": "project_goal",
      "severity": "high"
    }
  ],
  "missing_elements": ["budget", "timeline", "success_metrics"]
}
```

### BEAT Data Storage Details

```
club_data/classified/
â”œâ”€â”€ work/                           # Confirmed work messages
â”‚   â”œâ”€â”€ rishi2205/
â”‚   â”‚   â”œâ”€â”€ messages_001.jsonl
â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚   â”‚   â””â”€â”€ summary.json
â”‚   â”œâ”€â”€ syedislam/
â”‚   â””â”€â”€ [other-users]/
â”‚
â”œâ”€â”€ personal/                       # Removed from RAG
â”œâ”€â”€ spam/                           # Filtered out
â”œâ”€â”€ uncertain/                      # Flagged for review
â””â”€â”€ search_index.pkl               # TF-IDF vectors for all work docs
```

---

## 4. RAG IMPLEMENTATION (Enhanced RAG v2.1)

### RAG Pipeline Architecture

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Query Classification          â”‚
â”‚ - Detect query type             â”‚
â”‚ - Set retrieval parameters       â”‚
â”‚ - Choose weighting scheme        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Multi-Stage Retrieval        â”‚
â”‚ â”œâ”€ BM25 (keyword matching)      â”‚
â”‚ â”œâ”€ Semantic (embeddings)        â”‚
â”‚ â”œâ”€ Freshness weighting          â”‚
â”‚ â””â”€ Metadata filtering           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Re-ranking (Cross-Encoder)   â”‚
â”‚ - Score semantic relevance      â”‚
â”‚ - Keep top-5 sources            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Duplicate Removal            â”‚
â”‚ - MMR (Maximal Marginal Rel.)   â”‚
â”‚ - Diverse results               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Context Building             â”‚
â”‚ - Format top sources            â”‚
â”‚ - Include metadata              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Answer Generation (LLM)      â”‚
â”‚ - GPT-5-chat with context       â”‚
â”‚ - Include citations             â”‚
â”‚ - Temperature: 0.3              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Hallucination Detection      â”‚
â”‚ - Verify claims against sources â”‚
â”‚ - Flag unsupported statements   â”‚
â”‚ - Calculate citation coverage   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Answer + Sources
```

### Query Classification Types

| Type | Semantic Weight | BM25 Weight | Top K | MMR Lambda | Use Case |
|------|-----------------|-------------|-------|------------|----------|
| **Factual** | 75% | 25% | 12 | 0.8 | "What was the budget?" |
| **Exploratory** | 60% | 40% | 15 | 0.6 | "Tell me about the project" |
| **Comparative** | 65% | 35% | 20 | 0.5 | "Compare two projects" |
| **Procedural** | 70% | 30% | 12 | 0.7 | "How was it done?" |
| **Temporal** | 60% | 40% | 15 | 0.6 | "When did it happen?" |
| **Aggregation** | 55% | 45% | 20 | 0.5 | "List all projects" |

### RAG Components

1. **QueryClassifier** - Determines best retrieval strategy
2. **EmbeddingRetriever** - Semantic search using text-embedding-3-large
3. **BM25Retriever** - Keyword matching
4. **CrossEncoderReranker** - Scores retrieved documents (requires sentence-transformers)
5. **MMRSelector** - Maximal Marginal Relevance for diversity
6. **HallucinationDetector** - Verifies answers against sources
7. **TemporalWeighter** - Boosts recent documents
8. **ConversationContextManager** - Maintains chat history

### Configuration

```python
# app_universal.py
Config.TOP_K_RETRIEVAL = 10        # Initial retrieval
Config.RERANK_TOP_K = 5            # After re-ranking
Config.MAX_CONTEXT_LENGTH = 8000   # Context window
```

---

## 5. BACKEND API ENDPOINTS (43 Total)

### Core RAG & Search
- **`POST /api/search`** - RAG query with answer + sources
- **`GET /api/all-emails`** - Get all indexed documents
- **`GET /api/document/<doc_id>`** - Get document metadata
- **`GET /api/document/<doc_id>/view`** - View document content

### Knowledge Gaps & Questions
- **`GET /api/questions`** - List knowledge gaps
- **`GET /api/questions/generate`** - Generate new gap questions
- **`POST /api/questions/answer`** - Submit answer to gap question
- **`POST /api/questions/analyze-project`** - Analyze project for gaps
- **`GET /api/projects/<project_id>/gaps`** - Project-specific gaps

### Projects & Documents
- **`GET /api/projects`** - List all projects
- **`GET /api/projects/<project_id>`** - Project details
- **`GET /api/projects/<project_id>/documents`** - Project documents
- **`POST /api/projects/reprocess`** - Re-cluster projects
- **`POST /api/documents/upload`** - Upload new document
- **`GET /api/documents/review`** - Documents pending review
- **`POST /api/documents/<doc_id>/decision`** - Accept/reject document
- **`GET /api/documents/ready-for-rag`** - Approved documents
- **`GET /api/documents/stats`** - Document statistics
- **`GET /api/documents/categories`** - Document categories

### Connectors & Integrations
- **`GET /api/connectors`** - List connected sources
- **`POST /api/connectors/add`** - Add new connector
- **`GET /api/connectors/gmail/auth`** - Gmail OAuth flow
- **`GET /api/connectors/gmail/callback`** - OAuth callback
- **`GET /api/connectors/gmail/status`** - Connection status
- **`POST /api/connectors/gmail/disconnect`** - Disconnect source
- **`POST /api/connectors/gmail/sync`** - Sync new data

### Message Filtering
- **`GET /api/messages/review`** - Messages for manual review
- **`GET /api/messages/review/count`** - Count pending reviews
- **`POST /api/messages/decide`** - Classify message (work/personal)

### Stakeholder Graph
- **`GET /api/stakeholders`** - All people mentioned
- **`POST /api/stakeholders/query`** - Find person expertise
- **`GET /api/stakeholders/expertise`** - Person's skills
- **`GET /api/stakeholders/projects`** - Person's projects

### Spaces & Organization
- **`GET /api/spaces`** - User spaces/projects

### Analytics & Feedback
- **`GET /api/stats`** - System statistics
- **`POST /api/feedback`** - Record user feedback (thumbs up/down)
- **`GET /api/feedback/stats`** - Feedback analytics
- **`GET /api/training-materials`** - Generated training content

### Content Generation
- **`POST /api/gamma/generate`** - Generate presentation
- **`GET /api/gamma/preview-structure`** - Preview presentation

### Utilities
- **`POST /api/transcribe`** - Speech-to-text (Whisper)

---

## 6. KNOWLEDGE GAPS IDENTIFICATION & STORAGE

### Gap Analysis Process

```python
# gap_analyzer.py
class GapAnalyzer:
    def analyze_project_gaps(project_data):
        """
        1. Create project summary from documents
           - Count documents
           - Extract subjects, keywords, people, dates
           - Identify document types
        
        2. Identify gaps using LLM
           - Query: "What information is missing from these documents?"
           - Look for: goals, success criteria, outcomes, decisions, lessons
           - Flag: budget, timeline, stakeholders, risks
        
        3. Categorize gaps
           - project_goal: Project objectives missing
           - success_criteria: Metrics/KPIs missing
           - project_outcome: Final results missing
           - key_decision: Important decisions not documented
           - lesson_learned: Insights/learnings missing
           - stakeholder: Participant info missing
           - process: How it was done unclear
           - risk: Risk management not documented
        
        4. Assign severity
           - HIGH: Critical gaps affecting understanding
           - MEDIUM: Important but not critical
           - LOW: Nice-to-have information
        
        5. Return structured gaps for frontend
        """
```

### Gap Storage Format

```json
{
  "project_name": "BEAT Initiative",
  "gaps": [
    {
      "type": "project_goal",
      "description": "Project objectives and goals not clearly documented",
      "severity": "high",
      "is_standard": true
    },
    {
      "type": "success_criteria",
      "description": "Success metrics and KPIs not specified",
      "severity": "high",
      "is_standard": true
    }
  ],
  "questions": [
    {
      "question": "What were the primary objectives of this project?",
      "gap_type": "project_goal",
      "severity": "high",
      "answer": null  # Filled when user answers
    }
  ],
  "missing_elements": ["budget", "timeline", "stakeholder_list"]
}
```

### Gap Types (Standard Questions)

1. **project_goal** - "What were the project's main objectives?"
2. **success_criteria** - "How was success measured?"
3. **project_outcome** - "What was the final outcome?"
4. **key_decision** - "What were critical decisions made?"
5. **lesson_learned** - "What lessons were learned?"
6. **stakeholder** - "Who were the key stakeholders?"
7. **process** - "How was the process executed?"
8. **risk** - "What risks were identified and managed?"

### Frontend Gap Collection (KnowledgeGaps.tsx)

1. **Display gaps grouped by project**
2. **Show severity badges** (high/medium/low)
3. **Voice input for answers** (Whisper transcription)
4. **Text input for detailed answers**
5. **Progress tracking** (X of Y questions answered)
6. **Submit answers via** `POST /api/questions/answer`
7. **Store answers for exit interview/knowledge base**

---

## 7. DATA FLOW DIAGRAMS

### User Query Flow

```
Frontend (ChatInterface)
         â†“
   User enters query
         â†“
POST /api/search with {query: string}
         â†“
Backend (app_universal.py)
         â†“
enhanced_rag.search(query)
         â†“
â”œâ”€ Load search_index.pkl
â”œâ”€ Classify query type
â”œâ”€ BM25 retrieval
â”œâ”€ Semantic retrieval
â”œâ”€ Re-ranking
â”œâ”€ Deduplication (MMR)
â””â”€ LLM answer generation
         â†“
Return {
  answer: string,
  sources: [{doc_id, score, content, metadata}],
  confidence: float,
  citation_coverage: float
}
         â†“
Frontend displays answer with:
â”œâ”€ Main answer text
â”œâ”€ Source citations [links]
â””â”€ Source list below answer
```

### Document Ingestion Flow

```
Connector (Gmail/Slack/GitHub)
         â†“
Extract messages/files
         â†“
POST /api/documents/upload
         â†“
Backend:
â”œâ”€ Store in club_data/pending/
â”œâ”€ Extract metadata
â”œâ”€ Run classifier: work/personal/spam?
â””â”€ Store result
         â†“
Frontend (Documents page):
â”œâ”€ Show pending documents
â”œâ”€ User reviews classification
â”œâ”€ Clicks accept/reject
         â†“
POST /api/documents/{doc_id}/decision
         â†“
Approved docs:
â”œâ”€ Move to club_data/classified/work/
â”œâ”€ Add to search_index
â”œâ”€ Re-build indexes
â””â”€ Ready for RAG
```

### Gap Identification Flow

```
Project selected in UI
         â†“
POST /api/projects/{project_id}/gaps
         â†“
Backend:
â”œâ”€ Load project documents
â”œâ”€ GapAnalyzer.analyze_project_gaps()
â”œâ”€ Generate standard questions
â””â”€ LLM-based gap detection
         â†“
Return gaps with questions
         â†“
Frontend (KnowledgeGaps):
â”œâ”€ Display organized by project
â”œâ”€ Show severity indicators
â”œâ”€ Enable voice/text answers
         â†“
User answers questions
         â†“
POST /api/questions/answer with {
  gap_id: string,
  answer: string,
  project: string
}
         â†“
Backend stores answer for:
â”œâ”€ Knowledge base enrichment
â”œâ”€ Exit interview document
â””â”€ Future training materials
```

---

## 8. KEY TECHNOLOGIES & DEPENDENCIES

### Core ML/NLP Stack
- **Transformers** (4.30.0) - Language models, embeddings
- **Sentence-Transformers** (2.2.0) - Semantic search, cross-encoders
- **BERTopic** (0.15.0) - Topic modeling/clustering
- **UMAP** (0.5.3) - Dimensionality reduction
- **HDBSCAN** (0.8.29) - Density-based clustering

### LLM & Embeddings
- **Azure OpenAI** - GPT-5-chat (answers), text-embedding-3-large (search)
- **LlamaParse** - PDF/document parsing with OCR

### Databases & Indexes
- **ChromaDB** (0.4.0) - Vector database (optional)
- **Neo4j** (5.12.0) - Knowledge graph (optional)
- **Pickle files** - Search indexes, embeddings (primary)

### Frontend Stack
- **Next.js** 14.0.0 - React framework
- **Tailwind CSS** 3.3.5 - Styling
- **Axios** 1.6.0 - HTTP client

### Backend Stack
- **Flask** - Web framework
- **Flask-CORS** - Cross-origin requests
- **Pandas** - Data processing
- **NumPy** - Numerical computing
- **Scikit-learn** - ML utilities (TF-IDF, similarity)

### Content Generation
- **python-pptx** - PowerPoint creation
- **Pillow** - Image processing
- **MoviePy** - Video generation
- **gTTS** - Text-to-speech

---

## 9. CURRENT SYSTEM STATUS & CAPABILITIES

### Fully Implemented
- âœ… RAG search with answer generation
- âœ… Document classification (work/personal)
- âœ… Knowledge gap identification
- âœ… Chatbot interface with sources
- âœ… Feedback system (thumbs up/down)
- âœ… Gmail OAuth integration
- âœ… Voice input (Whisper)
- âœ… Project clustering
- âœ… Stakeholder relationship mapping

### Partially Implemented
- ğŸŸ¡ Slack integration (configured, not fully tested)
- ğŸŸ¡ GitHub integration (configured, not fully tested)
- ğŸŸ¡ Neo4j graph queries (queries generated, not connected)
- ğŸŸ¡ Video generation (infrastructure ready, not deployed)

### In Development
- ğŸ”„ Training guide generation
- ğŸ”„ Exit interview system
- ğŸ”„ Cross-project gap analysis
- ğŸ”„ Real-time sync optimization

### Known Limitations
- Search index is large (1.4GB) - slow initial load
- RAG v2.1 requires cross-encoder (optional dependency)
- Whisper transcription needs audio quality handling
- Gap questions are template-based, not fully personalized

---

## 10. CONFIGURATION & ENVIRONMENT

### Required Environment Variables (.env)
```
# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://rishi-mihfdoty-eastus2.cognitiveservices.azure.com
AZURE_OPENAI_API_KEY=<your-key>

# LlamaParse
LLAMAPARSE_API_KEY=<your-key>

# Neo4j (optional)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=<password>

# Gmail OAuth (optional)
GOOGLE_CLIENT_ID=<your-id>
GOOGLE_CLIENT_SECRET=<your-secret>
```

### Key Config Parameters (config.py)

```python
# Model settings
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"
LLM_MODEL = "gpt-4o-mini"

# Clustering
MIN_CLUSTER_SIZE = 5
UMAP_N_COMPONENTS = 5

# Classification confidence
WORK_CONFIDENCE_THRESHOLD = 0.85
PERSONAL_CONFIDENCE_THRESHOLD = 0.85

# RAG retrieval
TOP_K_RETRIEVAL = 10
RERANK_TOP_K = 5
MAX_CONTEXT_LENGTH = 8000

# Gap analysis
MAX_QUESTIONS_PER_PROJECT = 10
```

---

## 11. STARTUP INSTRUCTIONS

### Frontend
```bash
cd /Users/rishitjain/Downloads/2nd-brain/frontend
npm install
npm run dev
# Runs on http://localhost:3000
```

### Backend
```bash
cd /Users/rishitjain/Downloads/2nd-brain/backend
pip install -r requirements.txt
python app_universal.py
# Runs on http://localhost:5003
```

### Data Loading
- Backend automatically loads indices on startup:
  - `club_data/search_index.pkl` (BEAT data)
  - `data/search_index.pkl` (Enron data - optional)
  - `club_data/embedding_index.pkl` (if exists)

---

## 12. NOTABLE CODE FILES TO UNDERSTAND

### Must-Read Files
1. `/backend/app_universal.py` - Main backend, all endpoints
2. `/backend/rag/enhanced_rag_v2.py` - RAG implementation
3. `/frontend/components/chat/ChatInterface.tsx` - Chat UI
4. `/frontend/components/knowledge-gaps/KnowledgeGaps.tsx` - Gap collection
5. `/backend/gap_analysis/gap_analyzer.py` - Gap detection logic
6. `/backend/config/config.py` - All configuration

### Key Function Signatures

```python
# RAG Query
enhanced_rag.search(query: str) -> Dict[str, Any]
# Returns: {answer, sources, confidence, citation_coverage}

# Gap Analysis
gap_analyzer.analyze_project_gaps(project_data: Dict) -> Dict
# Returns: {gaps, questions, missing_elements}

# Document Classification
classifier.classify(content: str) -> Dict
# Returns: {type: 'work'|'personal'|'spam', confidence}
```

---

## 13. QUICK REFERENCE

### Data Paths
- BEAT club data: `/Users/rishitjain/Downloads/2nd-brain/backend/club_data/`
- Search indexes: `/Users/rishitjain/Downloads/2nd-brain/backend/club_data/search_index.pkl`
- Enron data: `/Users/rishitjain/Downloads/2nd-brain/backend/data/`
- Output/reports: `/Users/rishitjain/Downloads/2nd-brain/backend/output/`

### Important Ports
- Frontend: 3000
- Backend: 5003
- Neo4j: 7687 (if running locally)

### API Base URL
- From frontend: `http://localhost:5003/api`
- From backend: `http://localhost:5003/api`

---

**End of Architecture Summary**
**Last Updated: December 3, 2025**
